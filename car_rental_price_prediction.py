# -*- coding: utf-8 -*-
"""Car rental price prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kJ5s5FmRhuJCFCu0vFLxY-Ow9wyJU2Al

ANALYSIS AND PREDICTION OF CAR RENTAL PRICE
"""

!pip install xgboost
!pip install ipywidgets

#Importing the Python packages to be used
import os
import io
import re
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, OneHotEncoder
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.ticker as ticker

# Mount Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Defining paths
GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = './project final car rental/'
GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)
print('List files: ', os.listdir(GOOGLE_DRIVE_PATH))
DATA_PATH = os.path.join(GOOGLE_DRIVE_PATH, 'data')
rental = os.path.join(DATA_PATH, 'CarRentalDataV1.csv')
#rental = 'CarRentalDataV1.csv'
print('file name: ', rental)

rental = pd.read_csv(rental)

"""Cleaning and handling the missing values"""

print(rental.isnull().sum())

# Check for missing values in the dataframe
missing_values = rental.isnull().sum()

# Display the columns with missing values and their counts
print("Missing values before cleaning:")
print(missing_values[missing_values > 0])

# Handle missing values

# For 'fuelType', fill missing values with the most common fuel type
most_common_fuel = rental['fuelType'].mode()[0]
rental['fuelType'].fillna(most_common_fuel, inplace=True)

# For 'rating', fill missing values with the mean rating
mean_rating = rental['rating'].mean()
rental['rating'].fillna(mean_rating, inplace=True)

# Verify that there are no more missing values
missing_values_after_cleaning = rental.isnull().sum()
print("Missing values after cleaning:")
print(missing_values_after_cleaning[missing_values_after_cleaning > 0])

print(rental.isnull().sum())

rental.info()

rental['fuelType'] = rental['fuelType'].fillna('Unknow')

print("Head of the cleaned data:")
rental.head()

print("tail of the cleaned data:")
rental.tail()

# Display basic statistics of the dataset
print("\nBasic Statistics:")
print(rental.describe())

# Plot histograms for numerical columns
numerical_columns = rental.select_dtypes(include=['float64', 'int64']).columns
rental[numerical_columns].hist(figsize=(15, 10), bins=20, edgecolor='black')
plt.suptitle('Histograms of Numerical Columns')
plt.show()

# For 'fuelType', fill missing values with the most common fuel type
most_common_fuel = rental['fuelType'].mode()[0]
rental['fuelType'].fillna(most_common_fuel, inplace=True)

# For 'rating', fill missing values with the mean rating
mean_rating = rental['rating'].mean()
rental['rating'].fillna(mean_rating, inplace=True)

# Correlation matrix and heatmap
correlation_matrix = rental.corr(numeric_only=True)
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

"""Comparison of the fuel types with Vehicle Make

"""

# Compare fuel types with vehicle make using a count plot
plt.figure(figsize=(14, 8))
sns.countplot(data=rental, x='vehicle.type', hue='fuelType', palette='viridis')
plt.title('Comparison of Fuel Types with Vehicle Make')
plt.xlabel('Vehicle Make')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Fuel Type')
plt.show()

# Plot the horizontal bar chart
plt.figure(figsize=(14, 8))
sns.countplot(data=rental, y='vehicle.type', hue='fuelType', palette='viridis')
plt.title('Comparison of Fuel Types with Vehicle Make')
plt.xlabel('Count')
plt.ylabel('Vehicle Type')
plt.xticks(rotation=0)  # No rotation needed for horizontal bars
plt.legend(title='Fuel Type')
plt.show()

# Count the occurrences of each fuel type
fuel_type_counts = rental['fuelType'].value_counts()

# Plot the donut chart
plt.figure(figsize=(10, 6))
plt.pie(fuel_type_counts, labels=fuel_type_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette("viridis"), wedgeprops={'width':0.3})
plt.title('Fuel Type Distribution')
plt.gca().add_artist(plt.Circle((0, 0), 0.7, color='white'))  # Draw the center circle
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

"""Percentage of Fuel type distribution according to car models (pie chart)"""

# Count the occurrences of each fuel type
fuel_type_counts = rental['fuelType'].value_counts()

# Plot the pie chart
plt.figure(figsize=(10, 6))
plt.pie(fuel_type_counts, labels=fuel_type_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette("viridis"))
plt.title('Fuel Type Distribution')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

"""Total number of vehicle models and there total number of models available for rent"""

# Count the occurrences of each vehicle make
vehicle_make_counts = rental['vehicle.make'].value_counts()

# Plot the bar chart
plt.figure(figsize=(14, 8))
sns.barplot(x=vehicle_make_counts.index, y=vehicle_make_counts.values, palette='viridis')
plt.title('Vehicle Make Distribution')
plt.xlabel('Vehicle Make')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

# Standardize vehicle makes by converting to uppercase to count similar names as the same
rental['vehicle.make'] = rental['vehicle.make'].str.upper()

# Count the occurrences of each vehicle make
vehicle_make_counts = rental['vehicle.make'].value_counts()

# Sort the vehicle makes by count for a clearer bar chart
vehicle_make_counts_sorted = vehicle_make_counts.sort_values(ascending=False)

# Plot the bar chart with sorted vehicle makes
plt.figure(figsize=(14, 8))
plt.bar(vehicle_make_counts_sorted.index, vehicle_make_counts_sorted.values, color='skyblue')
plt.title('Vehicle Make Distribution')
plt.xlabel('Vehicle Make')
plt.ylabel('Count')
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.tight_layout()  # Adjust layout for better fit
plt.show()

"""Top 5 vehicle makes which has highest vehicles for rent"""

# Display and print top 5 vehicle makes
top_5_vehicle_makes = rental['vehicle.make'].value_counts().head(5)
print("Top 5 Vehicle Makes:")
print(top_5_vehicle_makes)

# Plot the bar chart for top 5 vehicle makes
plt.figure(figsize=(10, 6))
sns.barplot(x=top_5_vehicle_makes.index, y=top_5_vehicle_makes.values, palette='viridis')
plt.title('Top 5 Vehicle Makes')
plt.xlabel('Vehicle Make')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""Location state where the highest number of vehicles are rented"""

# Count the occurrences of each location state
location_state_counts = rental['location.state'].value_counts()

# Plot the bar chart
plt.figure(figsize=(14, 8))
sns.barplot(x=location_state_counts.index, y=location_state_counts.values, palette='viridis')
plt.title('Car Count per Location State')
plt.xlabel('Location State')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""Top 5 Location States by Car Count"""

# Display and print top 5 location states by car count
top_5_location_states = rental['location.state'].value_counts().head(5)
print("\nTop 5 Location States by Car Count:")
print(top_5_location_states)

# Plot the bar chart for top 5 location states
plt.figure(figsize=(10, 6))
sns.barplot(x=top_5_location_states.index, y=top_5_location_states.values, palette='viridis')
plt.title('Top 5 Location States by Car Count')
plt.xlabel('Location State')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""Top 5 vehicle makes which has highest daily rate for renting a vehicle"""

# Calculate the average daily rate for each vehicle make
avg_daily_rate_by_make = rental.groupby('vehicle.make')['rate.daily'].mean().sort_values(ascending=False).head(5)

# Display the top 5 vehicle makes with the highest average daily rate
print("Top 5 Vehicle Makes by Average Daily Rate:")
print(avg_daily_rate_by_make)

# Plot the bar chart for top 5 vehicle makes by average daily rate
plt.figure(figsize=(10, 6))
sns.barplot(x=avg_daily_rate_by_make.index, y=avg_daily_rate_by_make.values, palette='viridis')
plt.title('Top 5 Vehicle Makes by Average Daily Rate')
plt.xlabel('Vehicle Make')
plt.ylabel('Average Daily Rate')
plt.xticks(rotation=45)
plt.show()

"""Top car models under each car maker helping to make those avg daily rates"""

# Calculate the average daily rate for each vehicle make and model
avg_daily_rate_by_make_model = rental.groupby(['vehicle.make', 'vehicle.model'])['rate.daily'].mean().reset_index()

# Get the top 5 vehicle makes by average daily rate
top_5_makes = rental.groupby('vehicle.make')['rate.daily'].mean().sort_values(ascending=False).head(5).index

# Filter the dataframe to include only the top 5 makes
filtered_data = avg_daily_rate_by_make_model[avg_daily_rate_by_make_model['vehicle.make'].isin(top_5_makes)]

# Get the top 5 models under each of the top 5 makes
top_5_models_by_make = filtered_data.groupby('vehicle.make').apply(lambda x: x.nlargest(5, 'rate.daily')).reset_index(drop=True)

# Display the result
print("Top car models under each car maker helping to make those avg daily rates:")
print(top_5_models_by_make)

# Plot the result
plt.figure(figsize=(14, 8))
sns.barplot(data=top_5_models_by_make, x='vehicle.model', y='rate.daily', hue='vehicle.make', dodge=False, palette='viridis')
plt.title('Top Car Models by Average Daily Rate under Each Top Car Maker')
plt.xlabel('Vehicle Model')
plt.ylabel('Average Daily Rate')
plt.xticks(rotation=45)
plt.legend(title='Vehicle Make')
plt.show()

"""Top 5 Renting Car Makes and car models"""

# Calculate the top 5 renting car makes and models by count of rentals
top_5_makes = rental['vehicle.make'].value_counts().head(5)
top_5_models = rental['vehicle.model'].value_counts().head(5)

# Display the results
print("Top 5 Renting Car Makes:")
print(top_5_makes)
print("\nTop 5 Renting Car Models:")
print(top_5_models)

# Plot the top 5 renting car makes
plt.figure(figsize=(10, 6))
sns.barplot(x=top_5_makes.index, y=top_5_makes.values, palette='viridis')
plt.title('Top 5 Renting Car Makes')
plt.xlabel('Vehicle Make')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

# Plot the top 5 renting car models
plt.figure(figsize=(10, 6))
sns.barplot(x=top_5_models.index, y=top_5_models.values, palette='viridis')
plt.title('Top 5 Renting Car Models')
plt.xlabel('Vehicle Model')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""Cleaning of data before training and testing with the machine learning models"""

# Drop rows with any remaining missing values
rental.dropna(inplace=True)

# Define relevant columns
relevant_columns = [
    'fuelType', 'rating', 'renterTripsTaken', 'reviewCount',
    'location.city', 'location.state', 'location.latitude', 'location.longitude',
    'vehicle.make', 'vehicle.model', 'vehicle.type', 'vehicle.year', 'rate.daily'
]

# Create a clean dataframe with only the relevant columns
clean_data = rental[relevant_columns]

# Display the clean dataframe
print("Clean DataFrame with Relevant Columns:")
print(clean_data.head())

# Save the clean dataframe to a new CSV file

DATA_PATH1 = os.path.join(GOOGLE_DRIVE_PATH, 'data')
clean_file_path = os.path.join(DATA_PATH1, 'Cleaned_CarRentalData.csv')


#clean_file_path = '/Users/rahul/Desktop/project/Cleaned_CarRentalData.csv'
clean_data.to_csv(clean_file_path, index=False)
print(f"Clean data saved to {clean_file_path}")

clean_data.head()

# Specifying the predictor variables and assigning them to 'x_data'
x_data = clean_data.drop('rate.daily', axis=1)

# Specifying the target variable, rate.daily, and assigning it to 'y_data'
y_data = clean_data['rate.daily']

# Display the shapes of the predictor and target datasets
print("Shapes of Predictor and Target Datasets:")
print(f"x_data: {x_data.shape}")
print(f"y_data: {y_data.shape}")
print(x_data)
print(y_data)

# Performing data splitting to obtain a training set (80%) and testing set (20%)
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.80, random_state=0)

# Check the size of both sets
print('Number of training samples:', x_train.shape[0])
print('Number of testing samples:', x_test.shape[0])

#Identify and select predictor (X) and target (y) variables
X = clean_data.drop('rate.daily', axis=1)
y = clean_data['rate.daily']

#Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Identify numerical variables
num_vars = X.select_dtypes(include=['float64', 'int64']).columns.tolist()

#Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the training set
X_train.loc[:, num_vars] = scaler.fit_transform(X_train[num_vars])

# Transform the testing set
X_test.loc[:, num_vars] = scaler.transform(X_test[num_vars])

# Display the shapes of the scaled training and testing sets
print("Shapes of Scaled Training and Testing Sets:")
print(f"X_train: {X_train.shape}")
print(f"X_test: {X_test.shape}")

"""MULTIPLE REGRESSION MODEL"""

# Preprocess the data
# Identify numerical and categorical features
num_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()
cat_features = X.select_dtypes(include=['object']).columns.tolist()

# Create a column transformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', MinMaxScaler(), num_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
    ])

# Fit and transform the training data, and transform the testing data
X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

# Create a regression object
multireg_model = LinearRegression()

# Fit the model using the training data
multireg_model.fit(X_train, y_train)

# Generate predictions on the test set
y_pred = multireg_model.predict(X_test)

# Evaluate the model using the R-squared metric
R2_test = multireg_model.score(X_test, y_test)
print(f'The R-squared score for the multiple regression model is: r2={round(R2_test, 3)}')
# Evaluate the model using the Root Mean Squared Error (RMSE)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f'The Root Mean Squared Error (RMSE) for the multiple regression model is: RMSE={round(rmse, 3)}')

"""PREDICTION OF PRICE ACCORDING TO MULTIPLE REGRESSION MODEL"""

# Create a comparison DataFrame to compare actual prices and predicted prices
comparison_df = pd.DataFrame({'Actual Price of rental vehicle': y_test, 'Predicted Price of rental vehicle': y_pred})

# Display the comparison
print("\nComparison of Actual Prices and Predicted Prices of rental vehicles (Multi regression model):")
print(comparison_df.head(20))

"""COMPARISON OF THE ACTUAL AND PREDICTED PRICES (MULTIPLE REGRESSION MODEL)"""

# Visualize the distribution of actual vs. predicted prices
plt.figure(figsize=(10, 6))
ax1 = sns.kdeplot(y_test, label='Actual Values', color='green')
sns.kdeplot(y_pred, label='Predicted Values', color='orange', ax=ax1)

# Adding a title and labeling the axes
plt.title('Actual vs. Predicted Values for Vehicle Rental Prices\n(Multiple Regression Model)', fontsize=16)
plt.xlabel('Car Rental Price (in USD)', fontsize=12)
plt.ylabel('Distribution Density', fontsize=12)
plt.legend(loc='best')

# Adjusting the x-axis to display the prices in a reader-friendly format
ax1.xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:,.0f}'))
plt.xticks(rotation=45)

# Displaying the distribution plot
plt.show()

"""RANDOM FOREST"""

# Create a regression object
rf_model = RandomForestRegressor(random_state=0)

# Fit the model using the training data
rf_model.fit(X_train, y_train)

# Generate predictions on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model using the R-squared metric and RMSE
R2_test = rf_model.score(X_test, y_test)
rmse = mean_squared_error(y_test, y_pred, squared=False)
print(f'The R-squared score for the Random Forest model is: r2={round(R2_test, 3)}')
print(f'The Root Mean Squared Error (RMSE) for the Random Forest model is: RMSE={round(rmse, 3)}')

# Create a comparison DataFrame to compare actual prices and predicted prices
comparison_df = pd.DataFrame({'Actual Price of Rental Vehicle': y_test, 'Predicted Price of Rental Vehicle': y_pred})

# Display the comparison
print("\nComparison of Actual Prices and Predicted Prices of Rental Vehicle (Random Forest):")
print(comparison_df.head(20))

# Visualize the distribution of actual vs. predicted prices
plt.figure(figsize=(10, 6))
ax1 = sns.kdeplot(y_test, label='Actual Values', color='green')
sns.kdeplot(y_pred, label='Predicted Values', color='orange', ax=ax1)

# Adding a title and labeling the axes
plt.title('Actual vs. Predicted Values for Vehicle Rental Prices\n(Random Forest Model)', fontsize=16)
plt.xlabel('Vehichle Rental Price (in USD)', fontsize=12)
plt.ylabel('Distribution Density', fontsize=12)
plt.legend(loc='best')

# Adjusting the x-axis to display the prices in a reader-friendly format
ax1.xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:,.0f}'))
plt.xticks(rotation=45)

# Displaying the distribution plot
plt.show()

"""XGBOOST MODEL"""

# Create a regression object
xgb_model = XGBRegressor(random_state=0)

# Fit the model using the training data
xgb_model.fit(X_train, y_train)

# Generate predictions on the test set
y_pred = xgb_model.predict(X_test)

# Evaluate the model using the R-squared metric and RMSE
R2_test = r2_score(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
print(f'The R-squared score for the XGBoost model is: r2={round(R2_test, 3)}')
print(f'The Root Mean Squared Error (RMSE) for the XGBoost model is: RMSE={round(rmse, 3)}')

# Create a comparison DataFrame to compare actual prices and predicted prices
comparison_df = pd.DataFrame({'Actual Price of Rental vehicle': y_test, 'Predicted Price of Rental vehicle': y_pred})

# Display the comparison
print("\nComparison of Actual Prices and Predicted Prices of Rental Vehicle (XGBoost):")
print(comparison_df.head(20))

# Visualize the distribution of actual vs. predicted prices
plt.figure(figsize=(10, 6))
ax1 = sns.kdeplot(y_test, label='Actual Values', color='green')
sns.kdeplot(y_pred, label='Predicted Values', color='orange', ax=ax1)

# Adding a title and labeling the axes
plt.title('Actual vs. Predicted Values for Vehicle Rental Prices\n(XGBoost Model)', fontsize=16)
plt.xlabel('Vehicle Rental Price (in USD)', fontsize=12)
plt.ylabel('Distribution Density', fontsize=12)
plt.legend(loc='best')

# Adjusting the x-axis to display the prices in a reader-friendly format
ax1.xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:,.0f}'))
plt.xticks(rotation=45)

# Displaying the distribution plot
plt.show()

"""COMPARISON OF ALL THE MODELS USED FOR TRAINING AND TESTING"""

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Preprocess the data
# Identify numerical and categorical features
num_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()
cat_features = X.select_dtypes(include=['object']).columns.tolist()

# Create a column transformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', MinMaxScaler(), num_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
    ])

# Fit and transform the training data, and transform the testing data
X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

# Initialize models
models = {
    'Multi Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(random_state=0),
    'XGBoost': XGBRegressor(random_state=0)
}

# Dictionary to store evaluation results
results = {
    'Model': [],
    'R-squared': [],
    'RMSE': []
}

# Train and evaluate each model
for name, model in models.items():
    # Fit the model
    model.fit(X_train, y_train)

    # Generate predictions
    y_pred = model.predict(X_test)

    # Evaluate the model
    r2 = r2_score(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred, squared=False)

    # Store the results
    results['Model'].append(name)
    results['R-squared'].append(r2)
    results['RMSE'].append(rmse)

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Plot model comparison
plt.figure(figsize=(12, 6))

# Plot R-squared scores
plt.subplot(1, 2, 1)
sns.barplot(x='R-squared', y='Model', data=results_df, palette='viridis')
plt.title('Model Comparison (R-squared)')
plt.xlabel('R-squared Score')
plt.ylabel('Model')

# Plot RMSE scores
plt.subplot(1, 2, 2)
sns.barplot(x='RMSE', y='Model', data=results_df, palette='viridis')
plt.title('Model Comparison (RMSE)')
plt.xlabel('Root Mean Squared Error')
plt.ylabel('Model')

plt.tight_layout()
plt.show()

# Display the results
print(results_df)

"""Ensemble methods to improve XGBoost model (using bagging and boosting)"""

# Perform data splitting to obtain a training set (80%) and testing set (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=0)

# Identify numerical and categorical features
num_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()
cat_features = X.select_dtypes(include=['object']).columns.tolist()

# Create a column transformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', MinMaxScaler(), num_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
    ])

# Fit and transform the training data, and transform the testing data
X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

# Define the number of models for bagging
n_models = 10
random_seeds = np.random.randint(0, 10000, size=n_models)

# Train multiple XGBoost models with different random seeds
models = []
for seed in random_seeds:
    model = XGBRegressor(random_state=seed)
    model.fit(X_train, y_train)
    models.append(model)

# Generate predictions on the test set and average them
predictions = np.zeros((X_test.shape[0], n_models))
for i, model in enumerate(models):
    predictions[:, i] = model.predict(X_test)

y_pred = np.mean(predictions, axis=1)

# Evaluate the ensemble model using the R-squared metric and RMSE
R2_test = r2_score(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
print(f'The R-squared score for the ensemble XGBoost model is: r2={round(R2_test, 3)}')
print(f'The Root Mean Squared Error (RMSE) for the ensemble XGBoost model is: RMSE={round(rmse, 3)}')

"""PREPARING DATA FOR TRAINING THE FINAL MODEL WITH XGBOOST using randomized searchCV (hyperparameter tuning)"""

#First, preparing the data for training the final model
#specifying predictor variables
x_data = clean_data[['fuelType', 'rating','renterTripsTaken', 'reviewCount','location.city','location.state', 'location.latitude','location.longitude', 'vehicle.make', 'vehicle.model', 'vehicle.type', 'vehicle.year']]

#specifying the target variable
y_data = clean_data['rate.daily']

#extracting categorical and numerical variables and storing them in separate objects
# for processing them later separately
numerical_vars = x_data.select_dtypes(exclude='object').columns.tolist()
categorical_vars = x_data.select_dtypes(include='object').columns.tolist()

from sklearn.model_selection import train_test_split, RandomizedSearchCV
# Extract categorical and numerical variables
numerical_vars = x_data.select_dtypes(exclude='object').columns.tolist()
categorical_vars = x_data.select_dtypes(include='object').columns.tolist()

# Perform data splitting to obtain a training set (80%) and testing set (20%)
X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.80, random_state=0)

# Creating the first part of the pipeline for normalizing numerical variables
pipeline_pt1 = Pipeline([('Scaler', MinMaxScaler())])

# Creating the second part of the pipeline for encoding categorical variables
pipeline_pt2 = Pipeline([('Encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))])

# Combining both pipelines
pipeline_pt3 = ColumnTransformer([
    ('NumScaler', pipeline_pt1, numerical_vars),
    ('CatEncoder', pipeline_pt2, categorical_vars)
])

# Adding the XGBoost model to the pipeline
pipeline_prep = Pipeline([
    ('ColumnTransformer', pipeline_pt3),
    ('XGBoost', XGBRegressor(random_state=0))
])

# Define the parameter grid for RandomizedSearchCV
param_distributions = {
    'XGBoost__n_estimators': [100, 200, 300],
    'XGBoost__learning_rate': [0.01, 0.05, 0.1],
    'XGBoost__max_depth': [3, 5, 7],
    'XGBoost__min_child_weight': [1, 3],
    'XGBoost__subsample': [0.7, 0.8, 0.9],
    'XGBoost__colsample_bytree': [0.7, 0.8, 0.9]
}

# Perform RandomizedSearchCV to find the best hyperparameters
random_search = RandomizedSearchCV(pipeline_prep, param_distributions, n_iter=20, scoring='neg_mean_squared_error', cv=3, verbose=1, random_state=0, n_jobs=-1)
random_search.fit(X_train, y_train)

# Get the best model from RandomizedSearchCV
best_model = random_search.best_estimator_

# Generate predictions on the test set
y_pred = best_model.predict(X_test)

# Evaluate the model using the R-squared metric and RMSE
R2_test = r2_score(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
print(f'The R-squared score for the tuned XGBoost model is: r2={round(R2_test, 3)}')
print(f'The Root Mean Squared Error (RMSE) for the tuned XGBoost model is: RMSE={round(rmse, 3)}')

# Create a comparison DataFrame to compare actual prices and predicted prices
comparison_df = pd.DataFrame({'Actual Price of Rental vehicle': y_test, 'Predicted Price of Rental vehicle': y_pred})

# Display the comparison
print("\nComparison of Actual Prices and Predicted Prices of Rental Vehicle (XGBoost using hyperparameter tuning):")
print(comparison_df.head(20))

# Visualize the distribution of actual vs. predicted prices
plt.figure(figsize=(10, 6))
ax1 = sns.kdeplot(y_test, label='Actual Values', color='blue')
sns.kdeplot(y_pred, label='Predicted Values', color='orange', ax=ax1)

# Adding a title and labeling the axes
plt.title('Actual vs. Predicted Values for Vehicle Rental Prices\n(XGBoost Model (hyperparameter tuning)', fontsize=16)
plt.xlabel('Vehicle Rental Price (in USD)', fontsize=12)
plt.ylabel('Distribution Density', fontsize=12)
plt.legend(loc='best')

# Adjusting the x-axis to display the prices in a reader-friendly format
ax1.xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:,.0f}'))
plt.xticks(rotation=45)

# Displaying the distribution plot
plt.show()

"""TO FIT THE MODEL USING THE TRAINING DATA AND GENERATE PREDICTIONS ON TEST SET"""

# Adding the tuned XGBoost model to the pipeline
pipeline_prep = Pipeline([
    ('ColumnTransformer', pipeline_pt3),
    ('XGBoost', XGBRegressor(
        n_estimators=200,  # Use the best hyperparameters found from RandomizedSearchCV
        learning_rate=0.05,
        max_depth=5,
        min_child_weight=3,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=0
    ))
])

# Fit the model using the training data
pipeline_prep.fit(X_train, y_train)

# Generate predictions on the test set
y_pred = pipeline_prep.predict(X_test)

"""MAKING PREDICTION OF CAR RENTAL PRICE"""

#Defining the function
def MakePredictionRentalPrice(model, X_vars):
    """
    This function takes two inputs:
    'model' specifies the model to be used to generate the price predictions,
    'X_vars' specifies the car characteristics for each car to make the price prediction based on.
    It runs the prediction-making process and returns a table with the predicted prices for each car.
    """

    Y_pred = model.predict(X_vars)
    Y_pred_df = pd.Series(Y_pred, name='Predicted Prices').to_frame().apply(lambda series: series.apply(lambda price: '${:,.2f}'.format(price)))
    return Y_pred_df

#Extracting a random sample from the dataset and assigning it to 'X_display'
X_display = x_data.sample(10)

#Previewing the sample
X_display

#Now passing the data to the MakePrediction() function to get price predictions
MakePredictionRentalPrice(pipeline_prep, X_display)

#Reindex and add predicted prices to dataframe
sample_and_prediction, sample_and_prediction['Predicted Prices'] = X_display.reset_index(drop=True), MakePredictionRentalPrice(pipeline_prep, X_display)
sample_and_prediction

import pandas as pd

def MakePrediction_forUser(model, x_data):
    """This function asks the user for inputs for different car attributes:
        fuelType, rating, renterTripsTaken, reviewCount, location.city, location.state, location.latitude, location.longitude,
        vehicle.make, vehicle.model, vehicle.type, vehicle.year.

        After taking user input, the function returns a price prediction as best suited for these characteristics."""

    # Create empty dictionary for input values
    X_vars = dict()

    # Take user input for car characteristics
    while True:
        fuel_type = input(f"Enter fuel type {x_data['fuelType'].unique().tolist()}: ")
        if fuel_type not in x_data['fuelType'].unique().tolist():
            print(f"Invalid fuel type. Please select from the list.\n")
            continue
        break
    filtered_data = x_data[x_data['fuelType'] == fuel_type]

    while True:
        try:
            rating = float(input('Enter rating: '))
            break
        except:
            print('Invalid input. Rating must be a numerical value. Try again...\n')
            continue
    while True:
        try:
            renter_trips_taken = int(input('Enter renter trips taken: '))
            break
        except:
            print('Invalid input. Renter trips taken must be an integer. Try again...\n')
            continue
    while True:
        try:
            review_count = int(input('Enter review count: '))
            break
        except:
            print('Invalid input. Review count must be an integer. Try again...\n')
            continue
    while True:
        location_state = input(f"Enter location state {filtered_data['location.state'].unique().tolist()}: ")
        if location_state not in filtered_data['location.state'].unique().tolist():
            print(f"Invalid location state. Please select from the list.\n")
            continue
        break
    filtered_data = filtered_data[filtered_data['location.state'] == location_state]

    while True:
        location_city = input(f"Enter location city {filtered_data['location.city'].unique().tolist()}: ")
        if location_city not in filtered_data['location.city'].unique().tolist():
            print(f"Invalid location city. Please select from the list.\n")
            continue
        break
    filtered_data = filtered_data[filtered_data['location.city'] == location_city]






    while True:
        try:
            location_latitude = float(input(f"Enter location latitude {filtered_data['location.latitude'].unique().tolist()}: "))
            break
        except:
            print('Invalid input. Location latitude must be a numerical value. Try again...\n')
            continue
    while True:
        try:
            location_longitude = float(input(f"Enter location longitude {filtered_data['location.longitude'].unique().tolist()}: "))
            break
        except:
            print('Invalid input. Location longitude must be a numerical value. Try again...\n')
            continue

    available_makes = filtered_data['vehicle.make'].unique().tolist()
    while True:
        vehicle_make = input(f"Enter vehicle make {available_makes}: ")
        if vehicle_make not in available_makes:
            print(f"Invalid vehicle make. Please select from the list.\n")
            continue
        break
    filtered_data = filtered_data[filtered_data['vehicle.make'] == vehicle_make]

    available_models = filtered_data['vehicle.model'].unique().tolist()
    while True:
        vehicle_model = input(f"Enter vehicle model for {vehicle_make} {available_models}: ")
        if vehicle_model not in available_models:
            print(f"Invalid vehicle model. Please select from the list.\n")
            continue
        break
    filtered_data = filtered_data[filtered_data['vehicle.model'] == vehicle_model]

    available_types = filtered_data['vehicle.type'].unique().tolist()
    while True:
        vehicle_type = input(f"Enter vehicle type for {vehicle_make} {vehicle_model} {available_types}: ")
        if vehicle_type not in available_types:
            print(f"Invalid vehicle type. Please select from the list.\n")
            continue
        break
    while True:
        try:
            vehicle_year = int(input('Enter vehicle year: '))
            break
        except:
            print('Invalid input. Vehicle year must be an integer. Try again...\n')
            continue

    print('\n\n')

    # Adding values to dictionary
    X_vars['fuelType'] = [fuel_type]
    X_vars['rating'] = [rating]
    X_vars['renterTripsTaken'] = [renter_trips_taken]
    X_vars['reviewCount'] = [review_count]
    X_vars['location.city'] = [location_city]
    X_vars['location.state'] = [location_state]
    X_vars['location.latitude'] = [location_latitude]
    X_vars['location.longitude'] = [location_longitude]
    X_vars['vehicle.make'] = [vehicle_make]
    X_vars['vehicle.model'] = [vehicle_model]
    X_vars['vehicle.type'] = [vehicle_type]
    X_vars['vehicle.year'] = [vehicle_year]

    # Convert dictionary to dataframe
    df_X_vars = pd.DataFrame(X_vars)

    # Print all inputs
    for key, value in X_vars.items():
        print(f"{key}: {value[0]}")

    # Generate and return price prediction
    Y_pred = model.predict(df_X_vars)
    return 'For a vehicle with the given characteristics, the predicted rental price is: ${:,.2f}.'.format(Y_pred[0])

#Now we can use the function to produce a prediction from user input
MakePrediction_forUser(pipeline_prep, x_data)